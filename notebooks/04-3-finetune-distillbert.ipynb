{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/SSD_Data/active_projects/transformer_to_lstm\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['SEED'] = \"42\"\n",
    "\n",
    "import dataclasses\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import nlp\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    DistilBertForSequenceClassification\n",
    ")\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pytorch_helper_bot import (\n",
    "    BaseBot, MovingAverageStatsTrackerCallback,  CheckpointCallback,\n",
    "    LearningRateSchedulerCallback, MultiStageScheduler, Top1Accuracy,\n",
    "    LinearLR, Callback\n",
    ")\n",
    "\n",
    "try:\n",
    "    from apex import amp\n",
    "    APEX_AVAILABLE = True\n",
    "except ModuleNotFoundError:\n",
    "    APEX_AVAILABLE = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = Path(\"cache/\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SST2Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, entries_dict):\n",
    "        super().__init__()\n",
    "        self.entries_dict = entries_dict\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.entries_dict[\"label\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.entries_dict[\"input_ids\"][idx],\n",
    "            self.entries_dict[\"attention_mask\"][idx],\n",
    "            self.entries_dict[\"label\"][idx]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict, valid_dict, test_dict = torch.load(str(CACHE_DIR / \"distill-dicts.jbl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a PyTorch Dataloader around our dataset\n",
    "train_loader = torch.utils.data.DataLoader(SST2Dataset(train_dict), batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(SST2Dataset(valid_dict), batch_size=64, drop_last=False)\n",
    "test_loader = torch.utils.data.DataLoader(SST2Dataset(test_dict), batch_size=64, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_bert_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_bert_model = distill_bert_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(distill_bert_model.parameters(), lr=2e-5, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "if APEX_AVAILABLE:\n",
    "    distill_bert_model, optimizer = amp.initialize(\n",
    "        distill_bert_model, optimizer, opt_level=\"O1\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillTop1Accuracy(Top1Accuracy):\n",
    "    def __call__(self, truth, pred):\n",
    "        truth = truth[\"label\"]\n",
    "        return super().__call__(truth, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class SST2Bot(BaseBot):\n",
    "    log_dir = CACHE_DIR / \"logs\"\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "        self.loss_format = \"%.6f\"\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_prediction(output):\n",
    "        return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][07/01/2020 22:08:40] SEED: 42\n",
      "[INFO][07/01/2020 22:08:40] # of parameters: 66,955,010\n",
      "[INFO][07/01/2020 22:08:40] # of trainable parameters: 66,955,010\n"
     ]
    }
   ],
   "source": [
    "total_steps = len(train_loader) * 5\n",
    "\n",
    "checkpoints = CheckpointCallback(\n",
    "    keep_n_checkpoints=1,\n",
    "    checkpoint_dir=CACHE_DIR / \"distill_model_cache/\",\n",
    "    monitor_metric=\"loss\"\n",
    ")\n",
    "lr_durations = [\n",
    "    int(total_steps*0.2),\n",
    "    int(np.ceil(total_steps*0.8))\n",
    "]\n",
    "break_points = [0] + list(np.cumsum(lr_durations))[:-1]\n",
    "callbacks = [\n",
    "    MovingAverageStatsTrackerCallback(\n",
    "        avg_window=len(train_loader) // 8,\n",
    "        log_interval=len(train_loader) // 10\n",
    "    ),\n",
    "    LearningRateSchedulerCallback(\n",
    "        MultiStageScheduler(\n",
    "            [\n",
    "                LinearLR(optimizer, 0.01, lr_durations[0]),\n",
    "                CosineAnnealingLR(optimizer, lr_durations[1])\n",
    "            ],\n",
    "            start_at_epochs=break_points\n",
    "        )\n",
    "    ),\n",
    "    checkpoints\n",
    "]\n",
    "    \n",
    "bot = SST2Bot(\n",
    "    log_dir = CACHE_DIR / \"distill_logs\",\n",
    "    model=distill_bert_model, \n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader, \n",
    "    clip_grad=10.,\n",
    "    optimizer=optimizer, echo=True,\n",
    "    criterion=torch.nn.CrossEntropyLoss(),\n",
    "    callbacks=callbacks,\n",
    "    pbar=False, use_tensorboard=False,\n",
    "    use_amp=APEX_AVAILABLE,\n",
    "    metrics=(Top1Accuracy(),)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][07/01/2020 22:08:40] Optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 2e-05\n",
      "    lr: 2e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "[INFO][07/01/2020 22:08:40] Batches per epoch: 1053\n",
      "[INFO][07/01/2020 22:08:40] ====================Epoch 1====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][07/01/2020 22:08:50] Step   105 | loss 0.675354 | lr: 2.18e-06 | 0.099s per step\n",
      "[INFO][07/01/2020 22:09:00] Step   210 | loss 0.535189 | lr: 4.15e-06 | 0.094s per step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][07/01/2020 22:09:10] Step   315 | loss 0.330805 | lr: 6.13e-06 | 0.094s per step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][07/01/2020 22:09:20] Step   420 | loss 0.301018 | lr: 8.10e-06 | 0.095s per step\n",
      "[INFO][07/01/2020 22:09:30] Step   525 | loss 0.278078 | lr: 1.01e-05 | 0.090s per step\n",
      "[INFO][07/01/2020 22:09:30] Metrics at step 526:\n",
      "[INFO][07/01/2020 22:09:30] loss: 0.270641\n",
      "[INFO][07/01/2020 22:09:30] accuracy: 87.84%\n",
      "[INFO][07/01/2020 22:09:40] Step   630 | loss 0.264246 | lr: 1.21e-05 | 0.097s per step\n",
      "[INFO][07/01/2020 22:09:49] Step   735 | loss 0.243720 | lr: 1.40e-05 | 0.090s per step\n",
      "[INFO][07/01/2020 22:09:59] Step   840 | loss 0.237302 | lr: 1.60e-05 | 0.092s per step\n",
      "[INFO][07/01/2020 22:10:09] Step   945 | loss 0.222996 | lr: 1.80e-05 | 0.094s per step\n",
      "[INFO][07/01/2020 22:10:18] Step  1050 | loss 0.201085 | lr: 2.00e-05 | 0.092s per step\n",
      "[INFO][07/01/2020 22:10:19] Metrics at step 1052:\n",
      "[INFO][07/01/2020 22:10:19] loss: 0.261985\n",
      "[INFO][07/01/2020 22:10:19] accuracy: 90.37%\n",
      "[INFO][07/01/2020 22:10:20] ====================Epoch 2====================\n",
      "[INFO][07/01/2020 22:10:29] Step  1155 | loss 0.176346 | lr: 2.00e-05 | 0.100s per step\n",
      "[INFO][07/01/2020 22:10:39] Step  1260 | loss 0.167275 | lr: 1.99e-05 | 0.094s per step\n",
      "[INFO][07/01/2020 22:10:49] Step  1365 | loss 0.157947 | lr: 1.98e-05 | 0.093s per step\n",
      "[INFO][07/01/2020 22:10:58] Step  1470 | loss 0.163293 | lr: 1.96e-05 | 0.093s per step\n",
      "[INFO][07/01/2020 22:11:08] Step  1575 | loss 0.157804 | lr: 1.93e-05 | 0.095s per step\n",
      "[INFO][07/01/2020 22:11:09] Metrics at step 1578:\n",
      "[INFO][07/01/2020 22:11:09] loss: 0.308364\n",
      "[INFO][07/01/2020 22:11:09] accuracy: 89.91%\n",
      "[INFO][07/01/2020 22:11:18] Step  1680 | loss 0.153119 | lr: 1.90e-05 | 0.095s per step\n",
      "[INFO][07/01/2020 22:11:28] Step  1785 | loss 0.154148 | lr: 1.86e-05 | 0.091s per step\n",
      "[INFO][07/01/2020 22:11:38] Step  1890 | loss 0.153822 | lr: 1.82e-05 | 0.092s per step\n",
      "[INFO][07/01/2020 22:11:47] Step  1995 | loss 0.140619 | lr: 1.77e-05 | 0.093s per step\n",
      "[INFO][07/01/2020 22:11:57] Step  2100 | loss 0.153582 | lr: 1.71e-05 | 0.093s per step\n",
      "[INFO][07/01/2020 22:11:58] Metrics at step 2104:\n",
      "[INFO][07/01/2020 22:11:58] loss: 0.323864\n",
      "[INFO][07/01/2020 22:11:58] accuracy: 88.99%\n",
      "[INFO][07/01/2020 22:11:58] ====================Epoch 3====================\n",
      "[INFO][07/01/2020 22:12:07] Step  2205 | loss 0.112328 | lr: 1.66e-05 | 0.095s per step\n",
      "[INFO][07/01/2020 22:12:17] Step  2310 | loss 0.093732 | lr: 1.60e-05 | 0.091s per step\n",
      "[INFO][07/01/2020 22:12:26] Step  2415 | loss 0.095752 | lr: 1.53e-05 | 0.091s per step\n",
      "[INFO][07/01/2020 22:12:36] Step  2520 | loss 0.094949 | lr: 1.46e-05 | 0.092s per step\n",
      "[INFO][07/01/2020 22:12:46] Step  2625 | loss 0.109475 | lr: 1.39e-05 | 0.092s per step\n",
      "[INFO][07/01/2020 22:12:46] Metrics at step 2630:\n",
      "[INFO][07/01/2020 22:12:46] loss: 0.279710\n",
      "[INFO][07/01/2020 22:12:46] accuracy: 89.45%\n",
      "[INFO][07/01/2020 22:12:56] Step  2730 | loss 0.104187 | lr: 1.32e-05 | 0.095s per step\n",
      "[INFO][07/01/2020 22:13:05] Step  2835 | loss 0.101691 | lr: 1.24e-05 | 0.092s per step\n",
      "[INFO][07/01/2020 22:13:15] Step  2940 | loss 0.101702 | lr: 1.17e-05 | 0.091s per step\n",
      "[INFO][07/01/2020 22:13:24] Step  3045 | loss 0.103295 | lr: 1.09e-05 | 0.091s per step\n",
      "[INFO][07/01/2020 22:13:34] Step  3150 | loss 0.101436 | lr: 1.01e-05 | 0.091s per step\n",
      "[INFO][07/01/2020 22:13:35] Metrics at step 3156:\n",
      "[INFO][07/01/2020 22:13:35] loss: 0.300671\n",
      "[INFO][07/01/2020 22:13:35] accuracy: 89.91%\n",
      "[INFO][07/01/2020 22:13:35] ====================Epoch 4====================\n",
      "[INFO][07/01/2020 22:13:44] Step  3255 | loss 0.071061 | lr: 9.31e-06 | 0.093s per step\n",
      "[INFO][07/01/2020 22:13:53] Step  3360 | loss 0.068877 | lr: 8.53e-06 | 0.091s per step\n",
      "[INFO][07/01/2020 22:14:03] Step  3465 | loss 0.063256 | lr: 7.76e-06 | 0.091s per step\n",
      "[INFO][07/01/2020 22:14:12] Step  3570 | loss 0.066372 | lr: 7.00e-06 | 0.091s per step\n",
      "[INFO][07/01/2020 22:14:22] Step  3675 | loss 0.067223 | lr: 6.26e-06 | 0.091s per step\n",
      "[INFO][07/01/2020 22:14:23] Metrics at step 3682:\n",
      "[INFO][07/01/2020 22:14:23] loss: 0.341243\n",
      "[INFO][07/01/2020 22:14:23] accuracy: 89.45%\n",
      "[INFO][07/01/2020 22:14:32] Step  3780 | loss 0.069065 | lr: 5.55e-06 | 0.093s per step\n",
      "[INFO][07/01/2020 22:14:41] Step  3885 | loss 0.065374 | lr: 4.86e-06 | 0.091s per step\n",
      "[INFO][07/01/2020 22:14:51] Step  3990 | loss 0.065160 | lr: 4.21e-06 | 0.091s per step\n",
      "[INFO][07/01/2020 22:15:00] Step  4095 | loss 0.063288 | lr: 3.58e-06 | 0.091s per step\n",
      "[INFO][07/01/2020 22:15:10] Step  4200 | loss 0.063598 | lr: 3.00e-06 | 0.091s per step\n",
      "[INFO][07/01/2020 22:15:11] Metrics at step 4208:\n",
      "[INFO][07/01/2020 22:15:11] loss: 0.330781\n",
      "[INFO][07/01/2020 22:15:11] accuracy: 89.91%\n",
      "[INFO][07/01/2020 22:15:11] ====================Epoch 5====================\n",
      "[INFO][07/01/2020 22:15:19] Step  4305 | loss 0.051122 | lr: 2.47e-06 | 0.093s per step\n",
      "[INFO][07/01/2020 22:15:29] Step  4410 | loss 0.043126 | lr: 1.97e-06 | 0.091s per step\n",
      "[INFO][07/01/2020 22:15:39] Step  4515 | loss 0.046578 | lr: 1.53e-06 | 0.091s per step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][07/01/2020 22:15:48] Step  4620 | loss 0.043089 | lr: 1.14e-06 | 0.091s per step\n",
      "[INFO][07/01/2020 22:15:58] Step  4725 | loss 0.044284 | lr: 8.05e-07 | 0.092s per step\n",
      "[INFO][07/01/2020 22:15:59] Metrics at step 4734:\n",
      "[INFO][07/01/2020 22:15:59] loss: 0.368667\n",
      "[INFO][07/01/2020 22:15:59] accuracy: 89.22%\n",
      "[INFO][07/01/2020 22:16:08] Step  4830 | loss 0.048006 | lr: 5.25e-07 | 0.094s per step\n",
      "[INFO][07/01/2020 22:16:17] Step  4935 | loss 0.048634 | lr: 3.04e-07 | 0.091s per step\n",
      "[INFO][07/01/2020 22:16:27] Step  5040 | loss 0.051134 | lr: 1.42e-07 | 0.091s per step\n",
      "[INFO][07/01/2020 22:16:36] Step  5145 | loss 0.047391 | lr: 4.08e-08 | 0.091s per step\n",
      "[INFO][07/01/2020 22:16:46] Step  5250 | loss 0.043795 | lr: 7.13e-10 | 0.091s per step\n",
      "[INFO][07/01/2020 22:16:47] Metrics at step 5260:\n",
      "[INFO][07/01/2020 22:16:47] loss: 0.364545\n",
      "[INFO][07/01/2020 22:16:47] accuracy: 89.45%\n",
      "[INFO][07/01/2020 22:16:48] Training finished. Best step(s):\n",
      "[INFO][07/01/2020 22:16:48] loss: 0.261985 @ step 1052\n",
      "[INFO][07/01/2020 22:16:48] accuracy: 90.37% @ step 1052\n"
     ]
    }
   ],
   "source": [
    "print(total_steps)\n",
    "\n",
    "bot.train(\n",
    "    total_steps=total_steps,\n",
    "    checkpoint_interval=len(train_loader) // 2\n",
    ")\n",
    "bot.load_model(checkpoints.best_performers[0][1])\n",
    "checkpoints.remove_checkpoints(keep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': (0.26198503566444464, '0.261985'),\n",
       " 'accuracy': (-0.9036697247706422, '90.37%')}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.eval(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': (0.22761504229055632, '0.227615'),\n",
       " 'accuracy': (-0.9128440366972477, '91.28%')}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.eval(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
