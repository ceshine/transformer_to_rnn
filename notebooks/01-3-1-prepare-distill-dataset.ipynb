{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/SSD_Data/active_projects/transformer_to_lstm\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from pathlib import Path\n",
    "\n",
    "import nlp\n",
    "import torch\n",
    "# import joblib\n",
    "import numpy as np\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import BertForSequenceClassification\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from pytorch_helper_bot.bot import batch_to_device\n",
    "\n",
    "try:\n",
    "    from apex import amp\n",
    "    APEX_AVAILABLE = True\n",
    "except ModuleNotFoundError:\n",
    "    APEX_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = Path(\"cache/\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nlp.load_dataset('glue', \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize our training dataset\n",
    "def convert_to_features(example_batch):\n",
    "    # Tokenize contexts and questions (as pairs of inputs)\n",
    "    encodings = tokenizer.batch_encode_plus(example_batch['sentence'], pad_to_max_length=True, max_length=64)\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format our dataset to outputs torch.Tensor to train a pytorch model\n",
    "columns = ['input_ids', 'token_type_ids', 'attention_mask', \"label\"]\n",
    "for subset in (\"train\", \"validation\"): \n",
    "    dataset[subset] = dataset[subset].map(convert_to_features, batched=True)\n",
    "    dataset[subset].set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(str(CACHE_DIR / \"sst2_bert_uncased\")).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "if APEX_AVAILABLE:\n",
    "    model = amp.initialize(\n",
    "        model, opt_level=\"O1\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SST2Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, entries_dict):\n",
    "        super().__init__()\n",
    "        self.entries_dict = entries_dict\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.entries_dict[\"label\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.entries_dict[\"input_ids\"][idx],\n",
    "            self.entries_dict[\"attention_mask\"][idx],\n",
    "            self.entries_dict[\"token_type_ids\"][idx],\n",
    "            self.entries_dict[\"label\"][idx]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx, test_idx = train_test_split(list(range(len(dataset[\"validation\"]))), test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\n",
    "    \"input_ids\": dataset['train'][\"input_ids\"],\n",
    "    \"attention_mask\": dataset['train'][\"attention_mask\"],\n",
    "    \"token_type_ids\": dataset['train'][\"token_type_ids\"],\n",
    "    \"label\": dataset['train'][\"label\"]\n",
    "}\n",
    "valid_dict = {\n",
    "    \"input_ids\": dataset['validation'][\"input_ids\"][valid_idx],\n",
    "    \"attention_mask\": dataset['validation'][\"attention_mask\"][valid_idx],\n",
    "    \"token_type_ids\": dataset['validation'][\"token_type_ids\"][valid_idx],\n",
    "    \"label\": dataset['validation'][\"label\"][valid_idx]\n",
    "}\n",
    "test_dict = {\n",
    "    \"input_ids\": dataset['validation'][\"input_ids\"][test_idx],\n",
    "    \"attention_mask\": dataset['validation'][\"attention_mask\"][test_idx],\n",
    "    \"token_type_ids\": dataset['validation'][\"token_type_ids\"][test_idx],\n",
    "    \"label\": dataset['validation'][\"label\"][test_idx]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a PyTorch Dataloader around our dataset\n",
    "train_loader = torch.utils.data.DataLoader(SST2Dataset(train_dict), batch_size=32, shuffle=False, drop_last=False)\n",
    "valid_loader = torch.utils.data.DataLoader(SST2Dataset(valid_dict), batch_size=32, drop_last=False)\n",
    "test_loader = torch.utils.data.DataLoader(SST2Dataset(test_dict), batch_size=32, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2105/2105 [01:01<00:00, 34.14it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 36.15it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 35.80it/s]\n"
     ]
    }
   ],
   "source": [
    "logits = {}\n",
    "for subset, dataloader in ((\"train\", train_loader), (\"valid\", valid_loader), (\"test\", test_loader)):\n",
    "    results = []\n",
    "    for *batch, target in tqdm(dataloader):\n",
    "        results.append(model(*batch_to_device(batch, \"cuda\"))[0].detach().cpu())\n",
    "    logits[subset] = torch.cat(results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([67349, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[\"train\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict[\"logits\"] = logits[\"train\"]\n",
    "valid_dict[\"logits\"] = logits[\"valid\"]\n",
    "test_dict[\"logits\"] = logits[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save([train_dict, valid_dict, test_dict], str(CACHE_DIR / \"distill-dicts.jbl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('rapids': conda)",
   "language": "python",
   "name": "python37664bitrapidsconda05ea436670824d2ebed703c8c53b011e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
